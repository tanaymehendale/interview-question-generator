{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "OufdYrqhS5-4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gFcFzdu7Q52-",
        "outputId": "e48b4ff9-4bed-40d6-b88a-eb05a586f10f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.2/328.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.4/476.4 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.6/587.6 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain langchain-community langchain-google-genai pinecone-client langchain-pinecone pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keys and config"
      ],
      "metadata": {
        "id": "vMLKMi6HTIsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, time, json\n",
        "from datetime import datetime\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"PINECONE_API_KEY\"] = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "INDEX_NAME = \"resumetan1\"\n",
        "PINECONE_CLOUD = \"aws\"\n",
        "PINECONE_REGION = \"us-east-1\"\n",
        "\n",
        "RESUME_PDF_PATH = \"/content/Tanay_Mehendale_Resume_AI2.pdf\" # rename to your uploaded file\n",
        "RESUME_ID = f\"resume_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNfF57tUTHEC",
        "outputId": "26c0b983-01ac-432c-db20-a5b17e8852e4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4270604867.py:13: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  RESUME_ID = f\"resume_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "E4WbPzM7T2K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_pinecone import PineconeVectorStore"
      ],
      "metadata": {
        "id": "9Qx75r9eT5HC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load PDF"
      ],
      "metadata": {
        "id": "zPUJOYhcUAhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(RESUME_PDF_PATH)\n",
        "pages = loader.load()\n",
        "\n",
        "print(\"Pages:\", len(pages))\n",
        "print(\"Sample page snippet:\", pages[0].page_content[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLBagNgoT5uO",
        "outputId": "5df0cff6-e223-4219-caff-dab584cd6a0f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pages: 1\n",
            "Sample page snippet: Tanay Mehendale \n",
            "San Jose, CA (can relocate) | tanay.mehendale@tamu.edu | 979-344-3679 | LinkedIn/tanay-mehendale | Portfolio | GitHub \n",
            "SUMMARY \n",
            "AI focused Data Engineer with 2.5+ years of experience building systems using Python, LLMs, and cloud platforms. Hands-on \n",
            "experience designing AI agents, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking - Recursive Character Text Splitter"
      ],
      "metadata": {
        "id": "sEIysgVxUSh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=550,\n",
        "    chunk_overlap=80,\n",
        "    separators=[\n",
        "        \"\\nEXPERIENCE\\n\", \"\\nPROJECTS\\n\", \"\\nEDUCATION\\n\",  \"\\nSKILLS\\n\",\n",
        "        \"\\n\\n\", \"\\n\", \"•\", \"-\", \" \", \"\"\n",
        "    ],\n",
        ")\n",
        "chunks = splitter.split_documents(pages)\n",
        "print(\"Chunks:\", len(chunks))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K43btVF8UT96",
        "outputId": "e834752c-5adf-42a9-9fad-e771de9a110a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunks: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding"
      ],
      "metadata": {
        "id": "y3jm9hmAUcqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)\n",
        "\n",
        "LABEL_SET = [\"experience\", \"projects\", \"skills\", \"education\", \"other\"]\n",
        "\n",
        "def label_section(text: str) -> str:\n",
        "  prompt = (\"\"\"\n",
        "    You label resume text chunks.\n",
        "    Return exactly one lowercase label from this list: experience, projects, skills, education, other\n",
        "    Rules:\n",
        "    - Choose experience if the text looks like a job role with bullets, impacts, responsibilities.\n",
        "    - Choose projects if it describes a project, build, pipeline, dashboard, system.\n",
        "    - Choose skills if it is mostly tools, technologies, languages.\n",
        "    - Choose education if it is school, degree, coursework.\n",
        "    - Otherwise other.\n",
        "    Chunk:\n",
        "    {text[:2000]}\n",
        "    \"\"\")\n",
        "  out = llm.invoke(prompt).content.strip().lower()\n",
        "  out = re.sub(r\"[^a-z]\", \"\", out)\n",
        "  return out if out in LABEL_SET else \"other\"\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "def guess_section_rule(text: str) -> str | None:\n",
        "    t = text.lower()\n",
        "\n",
        "    # strong skills signal\n",
        "    if (\"skills\" in t and len(t) < 900) or (\"certifications\" in t) or (\"languages\" in t and \"python\" in t):\n",
        "        if sum(kw in t for kw in [\"python\", \"sql\", \"aws\", \"spark\", \"tableau\", \"kafka\", \"snowflake\"]) >= 3:\n",
        "            return \"skills\"\n",
        "\n",
        "    # strong projects signal\n",
        "    if \" | link\" in t or \"github\" in t or \"vercel\" in t or \"deployed\" in t:\n",
        "        return \"projects\"\n",
        "\n",
        "    # strong experience signals\n",
        "    has_dates = bool(re.search(r\"\\b(20\\d{2}|'\\d{2})\\b\", t)) or (\"present\" in t)\n",
        "    has_role_words = any(w in t for w in [\"intern\", \"engineer\", \"analyst\", \"developer\", \"assistant\"])\n",
        "    has_action_bullets = (\"•\" in text) or any(v in t for v in [\"built\", \"designed\", \"developed\", \"implemented\", \"optimized\", \"migrated\", \"reduced\", \"improved\"])\n",
        "\n",
        "    if (has_dates and has_role_words) or (has_role_words and has_action_bullets):\n",
        "        return \"experience\"\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "D-pl2ofkdDsV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_SET = [\"experience\", \"projects\", \"skills\", \"education\", \"other\"]\n",
        "\n",
        "def label_section_hybrid(text: str) -> str:\n",
        "    rule = guess_section_rule(text)\n",
        "    if rule:\n",
        "        return rule\n",
        "\n",
        "    prompt = (\n",
        "        \"Return exactly one label from: experience, projects, skills, education, other.\\n\"\n",
        "        \"You are labeling resume chunks.\\n\\n\"\n",
        "        \"Choose experience for job roles, responsibilities, impact bullets.\\n\"\n",
        "        \"Choose projects for named projects, systems, pipelines, dashboards, links.\\n\"\n",
        "        \"Choose skills for tool lists and certifications.\\n\"\n",
        "        \"Choose education for degree, university, graduation.\\n\\n\"\n",
        "        \"Return only the label.\\n\\n\"\n",
        "        f\"Chunk:\\n{text[:1500]}\"\n",
        "    )\n",
        "    out = llm.invoke(prompt).content.strip().lower()\n",
        "    out = re.sub(r\"[^a-z]\", \"\", out)\n",
        "    return out if out in LABEL_SET else \"other\"\n"
      ],
      "metadata": {
        "id": "5QZ8VUAjUi6b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metadata, id, label"
      ],
      "metadata": {
        "id": "yMgyNPwuUz6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import time\n",
        "\n",
        "for i, d in enumerate(chunks):\n",
        "    if d.metadata is None:\n",
        "        d.metadata = {}\n",
        "    d.metadata[\"doc_type\"] = \"resume\"\n",
        "    d.metadata[\"resume_id\"] = RESUME_ID\n",
        "    d.metadata[\"chunk_index\"] = i\n",
        "    d.metadata[\"chunk_id\"] = f\"{RESUME_ID}:c{i}\"\n",
        "\n",
        "for d in chunks:\n",
        "    d.metadata[\"section\"] = label_section_hybrid(d.page_content)\n",
        "    time.sleep(0.02)\n",
        "\n",
        "print(Counter([d.metadata.get(\"section\") for d in chunks]))\n",
        "\n",
        "# print 3 examples from each bucket so you can sanity check\n",
        "for sec in [\"experience\", \"projects\", \"skills\", \"other\"]:\n",
        "    print(\"\\nSECTION:\", sec)\n",
        "    shown = 0\n",
        "    for d in chunks:\n",
        "        if d.metadata.get(\"section\") == sec:\n",
        "            print(d.page_content[:220].replace(\"\\n\", \" \"))\n",
        "            shown += 1\n",
        "            if shown == 3:\n",
        "                break\n"
      ],
      "metadata": {
        "id": "T2zcpMk2a4H8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b323042-6dee-43d3-a880-2985b155bd0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'projects': 6, 'experience': 2, 'skills': 1})\n",
            "\n",
            "SECTION: experience\n",
            "EXPERIENCE  Data Engineer Intern – Texas A&M University | Remote, San Jose, CA Aug 2025 – Present   (Python, ETL, AWS, Data Pipelines, Data Modeling, Pandas, Sentiment Analysis)  • Architected a Python based ETL pipeline\n",
            "across 25+ subreddits to expand data coverage by 300%  • Optimized performance by resolving API failures, resulting in 100% data capture reliability and a 34% increase in speed  • Integrated LLM based sentiment analysis \n",
            "\n",
            "SECTION: projects\n",
            "Tanay Mehendale  San Jose, CA (can relocate) | tanay.mehendale@tamu.edu | 979-344-3679 | LinkedIn/tanay-mehendale | Portfolio | GitHub  SUMMARY  AI focused Data Engineer with 2.5+ years of experience building systems usi\n",
            "(SQL, Python, ETL, AWS, S3, Glue, Data Modeling, RCA)  • Developed 45+ custom ERP transactions using ABAP with SQL, improving data retrieval speed by 95% for 400+ users  • Diagnosed and resolved 30+ technical support iss\n",
            "issues by 84% across 52+ releases  PROJECTS  ApartmentFinder – AI Agent for Relocations | Link | AI Agents, RAG, LLM, MCP, GCP, Agentic AI, Google ADK  • Designed a multi-agent RAG based AI assistant using Google ADK, re\n",
            "\n",
            "SECTION: skills\n",
            "Relevant Courses: Database Management Systems, Machine Learnin g & Artificial Intelligence  SKILLS  Certifications: AWS Solutions Architect, Assoc. Data Engineer, Hackathons: Google AI Agents Intensive Hackathon  Program\n",
            "\n",
            "SECTION: other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = [d.metadata[\"chunk_id\"] for d in chunks]\n",
        "print(\"Unique IDs now:\", len(set(ids)))\n",
        "print(\"Sample IDs:\", ids[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyK30dy1buE5",
        "outputId": "fb4f1de8-06f1-44ca-cf62-4d5393165ddc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique IDs now: 9\n",
            "Sample IDs: ['resume_20251219_024419:c0', 'resume_20251219_024419:c1', 'resume_20251219_024419:c2', 'resume_20251219_024419:c3', 'resume_20251219_024419:c4', 'resume_20251219_024419:c5', 'resume_20251219_024419:c6', 'resume_20251219_024419:c7', 'resume_20251219_024419:c8']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Pinecone index"
      ],
      "metadata": {
        "id": "cGGkLxm0VNuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
        "\n",
        "test_vec = embeddings.embed_query(\"dimension test\")\n",
        "dim = len(test_vec)\n",
        "print(\"Embedding dimension:\", dim)\n",
        "\n",
        "existing = [idx[\"name\"] for idx in pc.list_indexes()]\n",
        "if INDEX_NAME not in existing:\n",
        "  pc.create_index(\n",
        "  name=INDEX_NAME,\n",
        "  dimension=dim,\n",
        "  metric=\"cosine\",\n",
        "  spec=ServerlessSpec(cloud=PINECONE_CLOUD, region=PINECONE_REGION),\n",
        "  )\n",
        "  print(\"Created index:\", INDEX_NAME)\n",
        "else:\n",
        "  print(\"Index already exists:\", INDEX_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvKcGyENVO09",
        "outputId": "defe1b06-839b-4486-e8df-f57bd46d57a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dimension: 768\n",
            "Created index: resumetan1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upsert chunks to Pinecone via LangChain"
      ],
      "metadata": {
        "id": "lUlA-84SVkjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)\n",
        "\n",
        "texts = [d.page_content for d in chunks]\n",
        "metadatas = [d.metadata for d in chunks]\n",
        "ids = [d.metadata[\"chunk_id\"] for d in chunks]\n",
        "\n",
        "vectorstore.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
        "\n",
        "print(\"Upsert complete. Total chunks indexed:\", len(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDFy6E1cVmLw",
        "outputId": "41c3042b-64df-4871-e8a1-1fd2d7abf965"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upsert complete. Total chunks indexed: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validating Chunk Retrieval and Connections"
      ],
      "metadata": {
        "id": "aACY-YMxVq77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
        "stats = pc.Index(INDEX_NAME).describe_index_stats()\n",
        "print(stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv5GLpWzYags",
        "outputId": "ab60c19d-1bce-483a-dd34-5ac14f1f6f9d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dimension': 768,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 9}},\n",
            " 'total_vector_count': 9,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pages:\", len(pages))\n",
        "print(\"Chunks:\", len(chunks))\n",
        "print(\"First 3 chunk lengths:\", [len(c.page_content) for c in chunks[:3]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmtqIi9wZWKP",
        "outputId": "058bfad6-cf9f-469d-ecb2-5b5debe0bcb1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pages: 1\n",
            "Chunks: 9\n",
            "First 3 chunk lengths: [516, 539, 455]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = [d.metadata.get(\"chunk_id\") for d in chunks]\n",
        "print(\"IDs count:\", len(ids))\n",
        "print(\"Unique IDs:\", len(set(ids)))\n",
        "print(\"Sample IDs:\", ids[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TInsS6L_ZXwQ",
        "outputId": "5ded304d-32e0-4bd7-f25e-b85abfe5590f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDs count: 9\n",
            "Unique IDs: 9\n",
            "Sample IDs: ['resume_20251219_024419:c0', 'resume_20251219_024419:c1', 'resume_20251219_024419:c2', 'resume_20251219_024419:c3', 'resume_20251219_024419:c4', 'resume_20251219_024419:c5', 'resume_20251219_024419:c6', 'resume_20251219_024419:c7', 'resume_20251219_024419:c8']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preview_hits(query: str, k: int = 5, section_filter=None):\n",
        "    flt = {\"doc_type\": \"resume\", \"resume_id\": RESUME_ID}\n",
        "\n",
        "    if section_filter is not None:\n",
        "        flt[\"section\"] = section_filter\n",
        "\n",
        "    hits = vectorstore.similarity_search_with_score(\n",
        "        query,\n",
        "        k=k,\n",
        "        filter=flt\n",
        "    )\n",
        "\n",
        "    print(\"Filter used:\", flt)\n",
        "    print(\"Hits returned:\", len(hits))\n",
        "    print()\n",
        "\n",
        "    for doc, score in hits:\n",
        "        cid = doc.metadata.get(\"chunk_id\")\n",
        "        sec = doc.metadata.get(\"section\")\n",
        "        print(\"score:\", round(float(score), 4), \"| section:\", sec, \"| id:\", cid)\n",
        "        print(doc.page_content[:180].replace(\"\\n\", \" \"))\n",
        "        print()\n",
        "\n",
        "    return hits\n"
      ],
      "metadata": {
        "id": "o9CzsYscVtK4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preview_hits(\"Kafka streaming pipeline\", k=5)\n",
        "preview_hits(\"Kafka streaming pipeline\", k=5, section_filter=\"experience\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxklyrZIYWZe",
        "outputId": "b3e05304-4bcc-45ca-e599-c175a8ab9d73"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filter used: {'doc_type': 'resume', 'resume_id': 'resume_20251219_024419'}\n",
            "Hits returned: 5\n",
            "\n",
            "score: 0.4549 | section: projects | id: resume_20251219_024419:c5\n",
            "• Developed an AI agent to tailor cover letters by matching user writing style, leveraged rapid prototyping in Cursor  InterviewBuddy | Link | RAG, Python, LLM, Generative AI, Gemi\n",
            "\n",
            "score: 0.4506 | section: experience | id: resume_20251219_024419:c1\n",
            "EXPERIENCE  Data Engineer Intern – Texas A&M University | Remote, San Jose, CA Aug 2025 – Present   (Python, ETL, AWS, Data Pipelines, Data Modeling, Pandas, Sentiment Analysis)  •\n",
            "\n",
            "score: 0.4188 | section: experience | id: resume_20251219_024419:c2\n",
            "across 25+ subreddits to expand data coverage by 300%  • Optimized performance by resolving API failures, resulting in 100% data capture reliability and a 34% increase in speed  • \n",
            "\n",
            "score: 0.4153 | section: projects | id: resume_20251219_024419:c4\n",
            "issues by 84% across 52+ releases  PROJECTS  ApartmentFinder – AI Agent for Relocations | Link | AI Agents, RAG, LLM, MCP, GCP, Agentic AI, Google ADK  • Designed a multi-agent RAG\n",
            "\n",
            "score: 0.413 | section: projects | id: resume_20251219_024419:c6\n",
            "sign-up health; Implemented anomaly detection logic to alert failures beyond traditional batch monitoring limits   ResQVision - Emergency Analytics | Link | React, D3.js, Node.js, \n",
            "\n",
            "Filter used: {'doc_type': 'resume', 'resume_id': 'resume_20251219_024419', 'section': 'experience'}\n",
            "Hits returned: 2\n",
            "\n",
            "score: 0.4506 | section: experience | id: resume_20251219_024419:c1\n",
            "EXPERIENCE  Data Engineer Intern – Texas A&M University | Remote, San Jose, CA Aug 2025 – Present   (Python, ETL, AWS, Data Pipelines, Data Modeling, Pandas, Sentiment Analysis)  •\n",
            "\n",
            "score: 0.4188 | section: experience | id: resume_20251219_024419:c2\n",
            "across 25+ subreddits to expand data coverage by 300%  • Optimized performance by resolving API failures, resulting in 100% data capture reliability and a 34% increase in speed  • \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(id='resume_20251219_024419:c1', metadata={'author': 'Resume Editing', 'chunk_id': 'resume_20251219_024419:c1', 'chunk_index': 1.0, 'creationdate': '2025-12-15T14:29:45-08:00', 'creator': 'Microsoft® Word 2021', 'doc_type': 'resume', 'moddate': '2025-12-15T14:29:45-08:00', 'page': 0.0, 'page_label': '1', 'producer': 'Microsoft® Word 2021', 'resume_id': 'resume_20251219_024419', 'section': 'experience', 'source': '/content/Tanay_Mehendale_Resume_AI2.pdf', 'total_pages': 1.0}, page_content='EXPERIENCE \\nData Engineer Intern – Texas A&M University | Remote, San Jose, CA Aug 2025 – Present \\n (Python, ETL, AWS, Data Pipelines, Data Modeling, Pandas, Sentiment Analysis) \\n• Architected a Python based ETL pipeline to consolidate 3 data sources into a multi-layer data lake on Amazon S3, \\nreducing data preparation time by 40% and aiding time series analysis \\n• Developed scalable logic to ingest 2M+ unstructured raw text via Reddit API, implementing regex-based alias matching \\nacross 25+ subreddits to expand data coverage by 300%'),\n",
              "  0.450598),\n",
              " (Document(id='resume_20251219_024419:c2', metadata={'author': 'Resume Editing', 'chunk_id': 'resume_20251219_024419:c2', 'chunk_index': 2.0, 'creationdate': '2025-12-15T14:29:45-08:00', 'creator': 'Microsoft® Word 2021', 'doc_type': 'resume', 'moddate': '2025-12-15T14:29:45-08:00', 'page': 0.0, 'page_label': '1', 'producer': 'Microsoft® Word 2021', 'resume_id': 'resume_20251219_024419', 'section': 'experience', 'source': '/content/Tanay_Mehendale_Resume_AI2.pdf', 'total_pages': 1.0}, page_content='across 25+ subreddits to expand data coverage by 300% \\n• Optimized performance by resolving API failures, resulting in 100% data capture reliability and a 34% increase in speed \\n• Integrated LLM based sentiment analysis to derive 12 distinct themes, creating high-value categorical features to \\nimprove segmentation and trend modeling \\nSoftware Engineer - Clarios | Mumbai, India Jan 2021 – Jun 2023 \\n (SQL, Python, ETL, AWS, S3, Glue, Data Modeling, RCA)'),\n",
              "  0.418763429)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Questions"
      ],
      "metadata": {
        "id": "tQLm9u3Sr-Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_resume_evidence(\n",
        "    query: str,\n",
        "    section: str,\n",
        "    resume_id: str,\n",
        "    top_k: int = 8\n",
        "):\n",
        "    flt = {\n",
        "        \"doc_type\": \"resume\",\n",
        "        \"resume_id\": resume_id,\n",
        "        \"section\": section\n",
        "    }\n",
        "\n",
        "    hits = vectorstore.similarity_search_with_score(\n",
        "        query,\n",
        "        k=top_k,\n",
        "        filter=flt\n",
        "    )\n",
        "\n",
        "    evidence = []\n",
        "    for doc, score in hits:\n",
        "        evidence.append({\n",
        "            \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
        "            \"section\": doc.metadata.get(\"section\"),\n",
        "            \"score\": float(score),\n",
        "            \"text\": doc.page_content\n",
        "        })\n",
        "\n",
        "    # Deduplicate by chunk_id\n",
        "    seen = {}\n",
        "    for e in evidence:\n",
        "        cid = e[\"chunk_id\"]\n",
        "        if cid not in seen or e[\"score\"] < seen[cid][\"score\"]:\n",
        "            seen[cid] = e\n",
        "\n",
        "    return list(seen.values())\n"
      ],
      "metadata": {
        "id": "9iQ0IdmCgyYm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts"
      ],
      "metadata": {
        "id": "iWzYKf0GsC2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell: Query-time RAG. One prompt. Resume-only. Pinecone already populated.\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Assumes these already exist in your notebook:\n",
        "# - vectorstore: PineconeVectorStore(index_name=..., embedding=embeddings)\n",
        "# - llm: ChatGoogleGenerativeAI(...)\n",
        "# - RESUME_ID: the resume_id you indexed (example: \"resume_20251219_021401\")\n",
        "\n",
        "USER_QUERY = \"Generate interview questions based on my resume.\"\n",
        "OUT_PATH = \"/content/interview_questions.md\"\n",
        "\n",
        "N_EXP = 1\n",
        "N_PROJ = 1\n",
        "N_SKILL = 1\n",
        "N_BEH = 2\n",
        "\n",
        "def _truncate(text: str, max_chars: int = 850) -> str:\n",
        "    text = (text or \"\").strip()\n",
        "    if len(text) <= max_chars:\n",
        "        return text\n",
        "    return text[:max_chars].rstrip() + \"...\"\n",
        "\n",
        "def _retrieve(section: str, query: str, top_k: int):\n",
        "    flt = {\"doc_type\": \"resume\", \"resume_id\": RESUME_ID, \"section\": section}\n",
        "    hits = vectorstore.similarity_search_with_score(query, k=top_k, filter=flt)\n",
        "\n",
        "    evidence = []\n",
        "    for doc, score in hits:\n",
        "        evidence.append({\n",
        "            \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
        "            \"section\": doc.metadata.get(\"section\"),\n",
        "            \"score\": float(score),\n",
        "            \"text\": doc.page_content\n",
        "        })\n",
        "\n",
        "    # Dedup by chunk_id, keep best score\n",
        "    best = {}\n",
        "    for e in evidence:\n",
        "        cid = e.get(\"chunk_id\")\n",
        "        if not cid:\n",
        "            continue\n",
        "        if cid not in best or e[\"score\"] < best[cid][\"score\"]:\n",
        "            best[cid] = e\n",
        "\n",
        "    out = list(best.values())\n",
        "    out.sort(key=lambda x: x[\"score\"])\n",
        "    return out\n",
        "\n",
        "def _format_block(evidence_list, empty_msg: str):\n",
        "    if not evidence_list:\n",
        "        return empty_msg\n",
        "    parts = []\n",
        "    for e in evidence_list:\n",
        "        parts.append(f\"[{e['chunk_id']}]\\n{_truncate(e['text'])}\")\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "def build_single_prompt(user_query: str, exp_block: str, proj_block: str, skill_block: str) -> str:\n",
        "    return f\"\"\"\n",
        "  You are an interview coach. You generate grounded interview practice content from resume evidence.\n",
        "\n",
        "  User request:\n",
        "  {user_query}\n",
        "\n",
        "  Resume evidence. This is the ONLY source of candidate facts. Do not use outside knowledge.\n",
        "  Each evidence item starts with an id in square brackets.\n",
        "\n",
        "  EXPERIENCE EVIDENCE:\n",
        "  {exp_block}\n",
        "\n",
        "  PROJECTS EVIDENCE:\n",
        "  {proj_block}\n",
        "\n",
        "  SKILLS EVIDENCE:\n",
        "  {skill_block}\n",
        "\n",
        "  Rules:\n",
        "  - Strict grounding. Do not invent employers, titles, dates, tools, metrics, or outcomes not in evidence.\n",
        "  - If a detail is needed for STAR and not present, write \"Missing detail:\" and state what is missing.\n",
        "  - Every question must include an Evidence line listing chunk ids used.\n",
        "  - Avoid repeating the same question phrasing.\n",
        "\n",
        "  Task:\n",
        "  Create a single interview prep pack with these sections:\n",
        "  1) Experience-Based Questions. Generate exactly {N_EXP} questions.\n",
        "  2) Project Deep Dive Questions. Generate exactly {N_PROJ} questions.\n",
        "  3) Skills Verification Questions. Generate exactly {N_SKILL} questions.\n",
        "  4) Behavioral Questions. Generate exactly {N_BEH} questions grounded in the resume evidence themes.\n",
        "\n",
        "  Output format. Return Markdown only:\n",
        "\n",
        "  # Resume-Based Interview Question Pack\n",
        "\n",
        "  ## Experience-Based Questions\n",
        "  ### Q1. {{Question}}\n",
        "  Why They'll Ask This:\n",
        "  {{Reason}}\n",
        "  How To Prepare:\n",
        "  - {{Tip 1}}\n",
        "  - {{Tip 2}}\n",
        "  Sample Answer (STAR):\n",
        "  Situation:\n",
        "  Task:\n",
        "  Action:\n",
        "  Result:\n",
        "  Evidence:\n",
        "  - [chunk_id]\n",
        "\n",
        "  Repeat Q2..Q{N_EXP}.\n",
        "\n",
        "  ## Project Deep Dive Questions\n",
        "  Same structure, Q1..Q{N_PROJ}.\n",
        "\n",
        "  ## Skills Verification Questions\n",
        "  No STAR required.\n",
        "  ### Q1. {{Question}}\n",
        "  Why They'll Ask This:\n",
        "  {{Reason}}\n",
        "  How To Prepare:\n",
        "  - {{Tip}}\n",
        "  Evidence:\n",
        "  - [chunk_id]\n",
        "\n",
        "  Repeat Q2..Q{N_SKILL}.\n",
        "\n",
        "  ## Behavioral Questions\n",
        "  Same structure as Experience, Q1..Q{N_BEH}.\n",
        "  \"\"\".strip()\n",
        "\n",
        "# 1) Retrieve capped evidence per section\n",
        "exp_evidence = _retrieve(\n",
        "    section=\"experience\",\n",
        "    query=\"work experience responsibilities impact achievements ownership debugging collaboration\",\n",
        "    top_k=2\n",
        ")\n",
        "\n",
        "proj_evidence = _retrieve(\n",
        "    section=\"projects\",\n",
        "    query=\"projects built designed implemented deployed pipeline dashboard system RAG vector database langchain\",\n",
        "    top_k=4\n",
        ")\n",
        "\n",
        "skill_evidence = _retrieve(\n",
        "    section=\"skills\",\n",
        "    query=\"skills technologies tools languages frameworks cloud databases\",\n",
        "    top_k=1\n",
        ")\n",
        "\n",
        "# 2) Format evidence blocks (truncate to control tokens)\n",
        "exp_block = _format_block(exp_evidence, \"None found in index for this section.\")\n",
        "proj_block = _format_block(proj_evidence, \"None found in index for this section.\")\n",
        "skill_block = _format_block(skill_evidence, \"None found in index for this section.\")\n",
        "\n",
        "# 3) Build one prompt and generate\n",
        "prompt = build_single_prompt(USER_QUERY, exp_block, proj_block, skill_block)\n",
        "result_md = llm.invoke(prompt).content\n",
        "\n",
        "# 4) Save to file\n",
        "Path(OUT_PATH).write_text(result_md, encoding=\"utf-8\")\n",
        "\n",
        "print(\"Resume ID:\", RESUME_ID)\n",
        "print(\"Experience chunks used:\", [e[\"chunk_id\"] for e in exp_evidence])\n",
        "print(\"Project chunks used:\", [e[\"chunk_id\"] for e in proj_evidence])\n",
        "print(\"Skills chunks used:\", [e[\"chunk_id\"] for e in skill_evidence])\n",
        "print(\"Saved:\", OUT_PATH)\n",
        "print()\n",
        "print(result_md[:1400])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuNFZyUrsCgv",
        "outputId": "e921d12b-812a-4f0a-f209-7fb8deb1de99"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume ID: resume_20251219_030037\n",
            "Experience chunks used: []\n",
            "Project chunks used: []\n",
            "Skills chunks used: []\n",
            "Saved: /content/interview_questions.md\n",
            "\n",
            "# Resume-Based Interview Question Pack\n",
            "\n",
            "## Experience-Based Questions\n",
            "### Q1. Can you tell me about a significant professional experience you've had that you believe showcases your capabilities?\n",
            "Why They'll Ask This: To understand your professional background and how you apply your skills in a real-world setting, even if not explicitly detailed on your resume. This helps them gauge your ability to articulate your past roles and responsibilities.\n",
            "How To Prepare:\n",
            "- Think of a relevant professional experience, ideally one that highlights skills pertinent to the role you're interviewing for.\n",
            "- Structure your answer using the STAR method, focusing on your specific contributions and the impact you made.\n",
            "Sample Answer (STAR):\n",
            "Situation: Missing detail: No professional experience is provided in your resume evidence to ground this answer.\n",
            "Task: Missing detail: No professional experience is provided in your resume evidence to ground this answer.\n",
            "Action: Missing detail: No professional experience is provided in your resume evidence to ground this answer.\n",
            "Result: Missing detail: No professional experience is provided in your resume evidence to ground this answer.\n",
            "Evidence:\n",
            "- No evidence found in resume for this section.\n",
            "\n",
            "## Project Deep Dive Questions\n",
            "### Q1. Describe a project you've worked on that you are particularly proud of. What was your role, and what were the key outcomes?\n",
            "Why They\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result_md)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4KlpVQMsWkk",
        "outputId": "a68f9f82-9b52-46da-94b4-e4438fb11086"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Resume-Based Interview Question Pack\n",
            "\n",
            "## Experience-Based Questions\n",
            "### Q1. Can you tell me about a significant professional experience you've had that you believe showcases your capabilities?\n",
            "Why They'll Ask This: To understand your professional background and how you apply your skills in a real-world setting, even if not explicitly detailed on your resume. This helps them gauge your ability to articulate your past roles and responsibilities.\n",
            "How To Prepare:\n",
            "- Think of a relevant professional experience, ideally one that highlights skills pertinent to the role you're interviewing for.\n",
            "- Structure your answer using the STAR method, focusing on your specific contributions and the impact you made.\n",
            "Sample Answer (STAR):\n",
            "Situation: Missing detail: No professional experience is provided in your resume evidence to ground this answer.\n",
            "Task: Missing detail: No professional experience is provided in your resume evidence to ground this answer.\n",
            "Action: Missing detail: No professional experience is provided in your resume evidence to ground this answer.\n",
            "Result: Missing detail: No professional experience is provided in your resume evidence to ground this answer.\n",
            "Evidence:\n",
            "- No evidence found in resume for this section.\n",
            "\n",
            "## Project Deep Dive Questions\n",
            "### Q1. Describe a project you've worked on that you are particularly proud of. What was your role, and what were the key outcomes?\n",
            "Why They'll Ask This: To assess your ability to manage projects, overcome challenges, and deliver results, even if specific project details aren't explicitly listed. This question explores your initiative and problem-solving approach.\n",
            "How To Prepare:\n",
            "- Choose a project where you played a significant role and can clearly articulate your contributions.\n",
            "- Be ready to discuss any challenges you faced and how you addressed them, as well as the measurable outcomes.\n",
            "Sample Answer (STAR):\n",
            "Situation: Missing detail: No project evidence is provided in your resume to ground this answer.\n",
            "Task: Missing detail: No project evidence is provided in your resume to ground this answer.\n",
            "Action: Missing detail: No project evidence is provided in your resume to ground this answer.\n",
            "Result: Missing detail: No project evidence is provided in your resume to ground this answer.\n",
            "Evidence:\n",
            "- No evidence found in resume for this section.\n",
            "\n",
            "## Skills Verification Questions\n",
            "### Q1. Based on the role you are applying for, what key skills do you believe are most critical for success, and how have you developed them?\n",
            "Why They'll Ask This: To understand your self-awareness regarding necessary skills for the target role and your commitment to professional development, especially since no specific skills are listed on your resume.\n",
            "How To Prepare:\n",
            "- Research the job description thoroughly to identify the essential skills required for the position.\n",
            "- Be prepared to discuss specific instances or experiences where you've gained, applied, or further developed these skills.\n",
            "Evidence:\n",
            "- No evidence found in resume for this section.\n",
            "\n",
            "## Behavioral Questions\n",
            "### Q1. Tell me about a time you faced a significant challenge or obstacle. How did you approach it, and what was the outcome?\n",
            "Why They'll Ask This: To evaluate your problem-solving skills, resilience, and ability to navigate difficult situations. Given the lack of specific evidence, this question helps uncover underlying competencies and how you react under pressure.\n",
            "How To Prepare:\n",
            "- Select a challenge where you played a clear role in identifying and overcoming the obstacle.\n",
            "- Focus on your thought process, the actions you took, and the positive outcome or key learning experience.\n",
            "Sample Answer (STAR):\n",
            "Situation: Missing detail: No resume evidence is provided to ground specific themes for behavioral questions.\n",
            "Task: Missing detail: No resume evidence is provided to ground specific themes for behavioral questions.\n",
            "Action: Missing detail: No resume evidence is provided to ground specific themes for behavioral questions.\n",
            "Result: Missing detail: No resume evidence is provided to ground specific themes for behavioral questions.\n",
            "Evidence:\n",
            "- No evidence found in resume to ground specific themes for behavioral questions.\n",
            "\n",
            "### Q2. Describe a situation where you had to work effectively as part of a team to achieve a common goal. What was your contribution?\n",
            "Why They'll Ask This: To assess your collaboration skills, ability to contribute in a group setting, and how you interact with others, without specific team-based projects or experiences listed. It highlights your capacity for teamwork.\n",
            "How To Prepare:\n",
            "- Choose an example where your contribution was clear and impactful within a team dynamic.\n",
            "- Highlight how you communicated, supported others, and worked towards the collective objective.\n",
            "Sample Answer (STAR):\n",
            "Situation: Missing detail: No resume evidence is provided to ground specific themes for behavioral questions.\n",
            "Task: Missing detail: No resume evidence is provided to ground specific themes for behavioral questions.\n",
            "Action: Missing detail: No resume evidence is provided to ground specific themes for behavioral questions.\n",
            "Result: Missing detail: No resume evidence is provided to ground specific themes for behavioral questions.\n",
            "Evidence:\n",
            "- No evidence found in resume to ground specific themes for behavioral questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NE-EOArgufcQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}